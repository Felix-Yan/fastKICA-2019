import tensorflow as tf
import numpy as np
import time
from tensorflow.python.client import timeline
import cProfile
from scipy.stats.stats import pearsonr   
import itertools
import matplotlib
matplotlib.use('TkAgg') 
import matplotlib.pyplot as plt
import preprocessing
import random
from scipy.stats.stats import pearsonr 
from scipy import interpolate
import sys
import matlab.engine
import JADEMethod
import FastICAMethod

# setenv CUDA_VISIBLE_DEVICES 0

# Supports all the experiments. Now supports passed arguments for starting and ending generations

## data is of the form 2*N

def amari_distance(P,Q):
	m = len(P)
	B = np.dot(np.linalg.inv(P),Q)
	B = np.absolute(B)
	sum1 = np.sum(B,axis=0)
	max1 = B.max(0)
	term1 = (np.sum(sum1/max1)-m)/(m-1)/m
	B = B.T
	sum2 = np.sum(B,axis=0)
	max2 = B.max(0)
	term2 = (np.sum(sum2/max2)-m)/(m-1)/m
	distance = (term1 + term2)/2 

	return distance	


num_arg = len(sys.argv)
args = sys.argv
low_bound = 0
upp_bound = 0

if num_arg > 1:
	low_bound = int(args[1])
	upp_bound = int(args[2])


n_sources = 2
# batch_size = 4000
Ns = 250
energy = 1

noisy = False
num_noise = 25

print('sample size:',Ns)


distance_list = []
repeat = 1
if upp_bound != 0:
	repeat = upp_bound
#set a seed for selecting distribution paris
random.seed(0)
np.random.seed(0)

print('lower bound:',low_bound) 
print('upper bound:',upp_bound)

## loading matrices and data
all_matrices = np.load('matrices_2.npy', mmap_mode='r')
# all_matrices = np.load('matrices_4.npy', mmap_mode='r')

all_data = np.load('2_250.npy', mmap_mode='r')
# all_data = np.load('2_1000.npy', mmap_mode='r')
# all_data = np.load('2_1000_seed1.npy', mmap_mode='r')
# all_data = np.load('2_1000_noisy_10.npy', mmap_mode='r')
# all_data = np.load('4_1000.npy', mmap_mode='r')
# all_data = np.load('4_4000.npy', mmap_mode='r')

eng = matlab.engine.start_matlab()
eng.addpath(r'fastKICA/',nargout=0)
eng.addpath(r'fastKICA/utils',nargout=0)

for i in range(low_bound,repeat):
	print('iteration:',i)

	# A = np.random.rand(n_sources,n_sources)*2 - 1 # A random mixing matrix ranged between [-1,1)
	A = all_matrices[i*n_sources:(i*n_sources+n_sources),:]
	print('mixing matrix is:')
	print(A)

	#benchmark test		
	S = all_data[i*n_sources:(i*n_sources+n_sources),:]


	#nomalize S to have unit norm
	normed = (S - S.mean(axis=1)[:,None] ) / S.std(axis=1)[:,None]

	## no normalization
	# normed = S


	#V is the observed signal mixture.
	V = np.dot(A,normed)

	if noisy:
		noise1 = random.sample(range(0, 1000), num_noise)
		noise2 = random.sample(range(0, 1000), num_noise)
		for index in range(num_noise):
			V[0,noise1[index]] += -5 + random.randint(0,1)*10
			V[1,noise2[index]] += -5 + random.randint(0,1)*10

	#Remove mean
	# data = preprocessing.mean_subtraction(V)

	#whitening
	data, whiteningMatrix = preprocessing.whitening(V)
	# data = np.transpose(data) #no transpose for fastKICA

	## no whitening
	# data = np.transpose(V)

	##initial weights generated by running JADE
	mixing,S = JADEMethod.cjade(data)
	Xin = np.linalg.inv(np.real(mixing.T))

	##initial weights generated by running FastICA
	# rounds = 1001
	# initials = FastICAMethod.run(data,n_sources,Ns,rounds)

	## use FastKICA
	maxiter = 20
	sigma = 0.5
	thresh = 1e-6
	MS = matlab.double(data.tolist())
	# Xin = np.random.rand(n_sources,n_sources)*2 - 1 # A random demixing matrix ranged between [-1,1)
	Xin_mat = matlab.double(Xin.tolist()) 
	# weights, XS, hsics = eng.fastkica(MS, Xin, maxiter, sigma, thresh)
	output = eng.fastkica(MS, Xin_mat, maxiter, sigma, thresh,nargout=3)
	# print(output[0])
	weights = np.asarray(output[0])
	# print(weights)

	## use Jade only
	# weights = Xin

	## use FastICA only
	# weights = initials

	Q1 = np.linalg.inv(weights.T)
	## with whitening
	Q2 = np.dot(whiteningMatrix,A)

	## without whitening
	# Q2 = A

	distance = amari_distance(Q1,Q2)*100
	print('distance Number ',i,' is: ', distance)
	distance_list.append(distance)

mean = np.mean(distance_list)
var = np.var(distance_list)
std = np.sqrt(var)

print('final result:')
print(mean)
print(std)
